{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59be976a",
   "metadata": {},
   "source": [
    "# IMPLEMENT K-NN from Scratch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59af5d",
   "metadata": {},
   "source": [
    "Checkpoint -----> [ABIDINE M'hamed Bilal]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2053d885",
   "metadata": {},
   "source": [
    "# 1. Handle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126168ef",
   "metadata": {},
   "source": [
    "Open the dataset from CSV and split it into test/train datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e981051",
   "metadata": {},
   "source": [
    "Open the dataset from CSV and split it into test/train datasets.\n",
    "The problem is comprised of 150 observations of iris flowers from three different species. There are 4 measurements of given flowers: sepal length, sepal width, petal length, and petal width, all in the same unit of centimeters. The predicted attribute is the species, which is one of Setosa, Versicolor, or Virginica.\n",
    "\n",
    "It is a standard dataset where the species is known for all instances. As such we can split the data into training and test datasets and use the results to evaluate our algorithm implementation. Good classification accuracy on this problem is above 90% correct, typically 96% or better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "07d56ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1, 3.5, 1.4, 0.2, Iris-setosa\n",
      "4.9, 3.0, 1.4, 0.2, Iris-setosa\n",
      "4.7, 3.2, 1.3, 0.2, Iris-setosa\n",
      "4.6, 3.1, 1.5, 0.2, Iris-setosa\n",
      "5.0, 3.6, 1.4, 0.2, Iris-setosa\n",
      "5.4, 3.9, 1.7, 0.4, Iris-setosa\n",
      "4.6, 3.4, 1.4, 0.3, Iris-setosa\n",
      "5.0, 3.4, 1.5, 0.2, Iris-setosa\n",
      "4.4, 2.9, 1.4, 0.2, Iris-setosa\n",
      "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
      "5.4, 3.7, 1.5, 0.2, Iris-setosa\n",
      "4.8, 3.4, 1.6, 0.2, Iris-setosa\n",
      "4.8, 3.0, 1.4, 0.1, Iris-setosa\n",
      "4.3, 3.0, 1.1, 0.1, Iris-setosa\n",
      "5.8, 4.0, 1.2, 0.2, Iris-setosa\n",
      "5.7, 4.4, 1.5, 0.4, Iris-setosa\n",
      "5.4, 3.9, 1.3, 0.4, Iris-setosa\n",
      "5.1, 3.5, 1.4, 0.3, Iris-setosa\n",
      "5.7, 3.8, 1.7, 0.3, Iris-setosa\n",
      "5.1, 3.8, 1.5, 0.3, Iris-setosa\n",
      "5.4, 3.4, 1.7, 0.2, Iris-setosa\n",
      "5.1, 3.7, 1.5, 0.4, Iris-setosa\n",
      "4.6, 3.6, 1.0, 0.2, Iris-setosa\n",
      "5.1, 3.3, 1.7, 0.5, Iris-setosa\n",
      "4.8, 3.4, 1.9, 0.2, Iris-setosa\n",
      "5.0, 3.0, 1.6, 0.2, Iris-setosa\n",
      "5.0, 3.4, 1.6, 0.4, Iris-setosa\n",
      "5.2, 3.5, 1.5, 0.2, Iris-setosa\n",
      "5.2, 3.4, 1.4, 0.2, Iris-setosa\n",
      "4.7, 3.2, 1.6, 0.2, Iris-setosa\n",
      "4.8, 3.1, 1.6, 0.2, Iris-setosa\n",
      "5.4, 3.4, 1.5, 0.4, Iris-setosa\n",
      "5.2, 4.1, 1.5, 0.1, Iris-setosa\n",
      "5.5, 4.2, 1.4, 0.2, Iris-setosa\n",
      "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
      "5.0, 3.2, 1.2, 0.2, Iris-setosa\n",
      "5.5, 3.5, 1.3, 0.2, Iris-setosa\n",
      "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
      "4.4, 3.0, 1.3, 0.2, Iris-setosa\n",
      "5.1, 3.4, 1.5, 0.2, Iris-setosa\n",
      "5.0, 3.5, 1.3, 0.3, Iris-setosa\n",
      "4.5, 2.3, 1.3, 0.3, Iris-setosa\n",
      "4.4, 3.2, 1.3, 0.2, Iris-setosa\n",
      "5.0, 3.5, 1.6, 0.6, Iris-setosa\n",
      "5.1, 3.8, 1.9, 0.4, Iris-setosa\n",
      "4.8, 3.0, 1.4, 0.3, Iris-setosa\n",
      "5.1, 3.8, 1.6, 0.2, Iris-setosa\n",
      "4.6, 3.2, 1.4, 0.2, Iris-setosa\n",
      "5.3, 3.7, 1.5, 0.2, Iris-setosa\n",
      "5.0, 3.3, 1.4, 0.2, Iris-setosa\n",
      "7.0, 3.2, 4.7, 1.4, Iris-versicolor\n",
      "6.4, 3.2, 4.5, 1.5, Iris-versicolor\n",
      "6.9, 3.1, 4.9, 1.5, Iris-versicolor\n",
      "5.5, 2.3, 4.0, 1.3, Iris-versicolor\n",
      "6.5, 2.8, 4.6, 1.5, Iris-versicolor\n",
      "5.7, 2.8, 4.5, 1.3, Iris-versicolor\n",
      "6.3, 3.3, 4.7, 1.6, Iris-versicolor\n",
      "4.9, 2.4, 3.3, 1.0, Iris-versicolor\n",
      "6.6, 2.9, 4.6, 1.3, Iris-versicolor\n",
      "5.2, 2.7, 3.9, 1.4, Iris-versicolor\n",
      "5.0, 2.0, 3.5, 1.0, Iris-versicolor\n",
      "5.9, 3.0, 4.2, 1.5, Iris-versicolor\n",
      "6.0, 2.2, 4.0, 1.0, Iris-versicolor\n",
      "6.1, 2.9, 4.7, 1.4, Iris-versicolor\n",
      "5.6, 2.9, 3.6, 1.3, Iris-versicolor\n",
      "6.7, 3.1, 4.4, 1.4, Iris-versicolor\n",
      "5.6, 3.0, 4.5, 1.5, Iris-versicolor\n",
      "5.8, 2.7, 4.1, 1.0, Iris-versicolor\n",
      "6.2, 2.2, 4.5, 1.5, Iris-versicolor\n",
      "5.6, 2.5, 3.9, 1.1, Iris-versicolor\n",
      "5.9, 3.2, 4.8, 1.8, Iris-versicolor\n",
      "6.1, 2.8, 4.0, 1.3, Iris-versicolor\n",
      "6.3, 2.5, 4.9, 1.5, Iris-versicolor\n",
      "6.1, 2.8, 4.7, 1.2, Iris-versicolor\n",
      "6.4, 2.9, 4.3, 1.3, Iris-versicolor\n",
      "6.6, 3.0, 4.4, 1.4, Iris-versicolor\n",
      "6.8, 2.8, 4.8, 1.4, Iris-versicolor\n",
      "6.7, 3.0, 5.0, 1.7, Iris-versicolor\n",
      "6.0, 2.9, 4.5, 1.5, Iris-versicolor\n",
      "5.7, 2.6, 3.5, 1.0, Iris-versicolor\n",
      "5.5, 2.4, 3.8, 1.1, Iris-versicolor\n",
      "5.5, 2.4, 3.7, 1.0, Iris-versicolor\n",
      "5.8, 2.7, 3.9, 1.2, Iris-versicolor\n",
      "6.0, 2.7, 5.1, 1.6, Iris-versicolor\n",
      "5.4, 3.0, 4.5, 1.5, Iris-versicolor\n",
      "6.0, 3.4, 4.5, 1.6, Iris-versicolor\n",
      "6.7, 3.1, 4.7, 1.5, Iris-versicolor\n",
      "6.3, 2.3, 4.4, 1.3, Iris-versicolor\n",
      "5.6, 3.0, 4.1, 1.3, Iris-versicolor\n",
      "5.5, 2.5, 4.0, 1.3, Iris-versicolor\n",
      "5.5, 2.6, 4.4, 1.2, Iris-versicolor\n",
      "6.1, 3.0, 4.6, 1.4, Iris-versicolor\n",
      "5.8, 2.6, 4.0, 1.2, Iris-versicolor\n",
      "5.0, 2.3, 3.3, 1.0, Iris-versicolor\n",
      "5.6, 2.7, 4.2, 1.3, Iris-versicolor\n",
      "5.7, 3.0, 4.2, 1.2, Iris-versicolor\n",
      "5.7, 2.9, 4.2, 1.3, Iris-versicolor\n",
      "6.2, 2.9, 4.3, 1.3, Iris-versicolor\n",
      "5.1, 2.5, 3.0, 1.1, Iris-versicolor\n",
      "5.7, 2.8, 4.1, 1.3, Iris-versicolor\n",
      "6.3, 3.3, 6.0, 2.5, Iris-virginica\n",
      "5.8, 2.7, 5.1, 1.9, Iris-virginica\n",
      "7.1, 3.0, 5.9, 2.1, Iris-virginica\n",
      "6.3, 2.9, 5.6, 1.8, Iris-virginica\n",
      "6.5, 3.0, 5.8, 2.2, Iris-virginica\n",
      "7.6, 3.0, 6.6, 2.1, Iris-virginica\n",
      "4.9, 2.5, 4.5, 1.7, Iris-virginica\n",
      "7.3, 2.9, 6.3, 1.8, Iris-virginica\n",
      "6.7, 2.5, 5.8, 1.8, Iris-virginica\n",
      "7.2, 3.6, 6.1, 2.5, Iris-virginica\n",
      "6.5, 3.2, 5.1, 2.0, Iris-virginica\n",
      "6.4, 2.7, 5.3, 1.9, Iris-virginica\n",
      "6.8, 3.0, 5.5, 2.1, Iris-virginica\n",
      "5.7, 2.5, 5.0, 2.0, Iris-virginica\n",
      "5.8, 2.8, 5.1, 2.4, Iris-virginica\n",
      "6.4, 3.2, 5.3, 2.3, Iris-virginica\n",
      "6.5, 3.0, 5.5, 1.8, Iris-virginica\n",
      "7.7, 3.8, 6.7, 2.2, Iris-virginica\n",
      "7.7, 2.6, 6.9, 2.3, Iris-virginica\n",
      "6.0, 2.2, 5.0, 1.5, Iris-virginica\n",
      "6.9, 3.2, 5.7, 2.3, Iris-virginica\n",
      "5.6, 2.8, 4.9, 2.0, Iris-virginica\n",
      "7.7, 2.8, 6.7, 2.0, Iris-virginica\n",
      "6.3, 2.7, 4.9, 1.8, Iris-virginica\n",
      "6.7, 3.3, 5.7, 2.1, Iris-virginica\n",
      "7.2, 3.2, 6.0, 1.8, Iris-virginica\n",
      "6.2, 2.8, 4.8, 1.8, Iris-virginica\n",
      "6.1, 3.0, 4.9, 1.8, Iris-virginica\n",
      "6.4, 2.8, 5.6, 2.1, Iris-virginica\n",
      "7.2, 3.0, 5.8, 1.6, Iris-virginica\n",
      "7.4, 2.8, 6.1, 1.9, Iris-virginica\n",
      "7.9, 3.8, 6.4, 2.0, Iris-virginica\n",
      "6.4, 2.8, 5.6, 2.2, Iris-virginica\n",
      "6.3, 2.8, 5.1, 1.5, Iris-virginica\n",
      "6.1, 2.6, 5.6, 1.4, Iris-virginica\n",
      "7.7, 3.0, 6.1, 2.3, Iris-virginica\n",
      "6.3, 3.4, 5.6, 2.4, Iris-virginica\n",
      "6.4, 3.1, 5.5, 1.8, Iris-virginica\n",
      "6.0, 3.0, 4.8, 1.8, Iris-virginica\n",
      "6.9, 3.1, 5.4, 2.1, Iris-virginica\n",
      "6.7, 3.1, 5.6, 2.4, Iris-virginica\n",
      "6.9, 3.1, 5.1, 2.3, Iris-virginica\n",
      "5.8, 2.7, 5.1, 1.9, Iris-virginica\n",
      "6.8, 3.2, 5.9, 2.3, Iris-virginica\n",
      "6.7, 3.3, 5.7, 2.5, Iris-virginica\n",
      "6.7, 3.0, 5.2, 2.3, Iris-virginica\n",
      "6.3, 2.5, 5.0, 1.9, Iris-virginica\n",
      "6.5, 3.0, 5.2, 2.0, Iris-virginica\n",
      "6.2, 3.4, 5.4, 2.3, Iris-virginica\n",
      "5.9, 3.0, 5.1, 1.8, Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('iris.data.txt', 'r') as csvfile:\n",
    "    #  Use the csv.reader object to read the CSV file\n",
    "    lines = csv.reader(csvfile)\n",
    "    # lines = csv.reader(csvfile, delimiter = ',')\n",
    "    row=[]\n",
    "    for row in lines:\n",
    "        # row.append(row)\n",
    "        print(', '.join(row))\n",
    "\n",
    "# join elements of text with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "04fe27a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 384\n",
      "Test: 212\n"
     ]
    }
   ],
   "source": [
    "# Next we need to split the data into a training dataset \n",
    "import random\n",
    "\n",
    "def loadDataset(filename, split, trainingSet=[] , testSet=[]):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "    for x in range(len(dataset)-1):\n",
    "        for y in range(4):\n",
    "            dataset[x][y] = float(dataset[x][y])\n",
    "            if random.random() < split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])\n",
    "\n",
    "# We can test this function out with our iris dataset, as follows:\n",
    "\n",
    "trainingSet=[]\n",
    "testSet=[]\n",
    "loadDataset('iris.data.txt', 0.66, trainingSet, testSet)\n",
    "print('Train: ' + repr(len(trainingSet)))\n",
    "print('Test: ' + repr(len(testSet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806716e7",
   "metadata": {},
   "source": [
    "# 2. Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d812b4",
   "metadata": {},
   "source": [
    "Calculate the distance between two data instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4eeab3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def euclideanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow((instance1[x] - instance2[x]), 2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032be49",
   "metadata": {},
   "source": [
    "# 3. Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e073b8",
   "metadata": {},
   "source": [
    "Locate k most similar data instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ce0408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key = operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f65c2",
   "metadata": {},
   "source": [
    "# 4. Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c18777",
   "metadata": {},
   "source": [
    "Generate a response from a set of data instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6d61c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(neighbors):\n",
    "    # Creating a list with all the possible neighbors\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4c492",
   "metadata": {},
   "source": [
    "# 5. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516190d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Summarize the accuracy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e714e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210044b",
   "metadata": {},
   "source": [
    "# 6. Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42622988",
   "metadata": {},
   "source": [
    "Tie it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9c59c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  100.0\n",
      "Train set: 384\n",
      "Test set: 212\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def main():\n",
    "    #trainingSet=[]\n",
    "    #testSet=[]\n",
    "    #split = 0.66\n",
    "    #loadDataset('iris.data.txt', split, trainingSet, testSet)\n",
    "    print('Train set: ' + repr(len(trainingSet)))\n",
    "    print('Test set: ' + repr(len(testSet)) )   \n",
    "    predictions=[]\n",
    "    k = 3\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        #print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    \n",
    "print('Accuracy: ', accuracy)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128664dd",
   "metadata": {},
   "source": [
    "# 7. Another distance metric (Manhattan_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a193f0f",
   "metadata": {},
   "source": [
    "In this part, you are asked to define another distance metric instead of euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "31f88ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the manhattan distance between two points\n",
    "# assuming both to have the same number of dimensions\n",
    "def manhattanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += abs(instance1[x] - instance2[x])\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "64f4730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getneighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = manhattanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key = operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "aa653b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 384\n",
      "Test set: 212\n",
      "Accuracy:  95.28301886792453\n"
     ]
    }
   ],
   "source": [
    "def main1():\n",
    "    #trainingSet=[]\n",
    "    #testSet=[]\n",
    "    #split = 0.66\n",
    "    #loadDataset('iris.data.txt', split, trainingSet, testSet)\n",
    "    print('Train set: ' + repr(len(trainingSet)))\n",
    "    print('Test set: ' + repr(len(testSet)))   \n",
    "    predictions=[]\n",
    "    k = 3\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getneighbors(trainingSet, testSet[x], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        #print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: ', accuracy)\n",
    "    \n",
    "main1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742014a",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "For the small dimensionality as in Iris dataset, the Euclidean distance (Acc=100%) is better than Manhattan distance (Acc= 95.28%). Manhattan distance is usually preferred over the more common Euclidean distance when there is high dimensionality in the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
